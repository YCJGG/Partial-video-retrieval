nohup: ignoring input
###training start~~~~
hash_gan.py:285: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number
  epoch, itr, len(train_loader)*opt.batch_size, loss_d.data[0], loss_g.data[0]))
===> Epoch[0](0/58368): Loss_D: 127.6437454 Loss_G: 0.5211
===> Epoch[0](1/58368): Loss_D: 127.4384842 Loss_G: 0.5040
===> Epoch[0](2/58368): Loss_D: 127.2646942 Loss_G: 0.4876
===> Epoch[0](3/58368): Loss_D: 126.9475403 Loss_G: 0.4746
===> Epoch[0](4/58368): Loss_D: 126.6490707 Loss_G: 0.4621
===> Epoch[0](5/58368): Loss_D: 126.5959702 Loss_G: 0.4522
===> Epoch[0](6/58368): Loss_D: 126.3654022 Loss_G: 0.4429
===> Epoch[0](7/58368): Loss_D: 125.9008560 Loss_G: 0.4365
===> Epoch[0](8/58368): Loss_D: 126.1128998 Loss_G: 0.4308
===> Epoch[0](9/58368): Loss_D: 125.7341614 Loss_G: 0.4257
===> Epoch[0](10/58368): Loss_D: 125.5368271 Loss_G: 0.4235
===> Epoch[0](11/58368): Loss_D: 125.5131378 Loss_G: 0.4214
===> Epoch[0](12/58368): Loss_D: 125.6124802 Loss_G: 0.4190
===> Epoch[0](13/58368): Loss_D: 125.3331757 Loss_G: 0.4177
===> Epoch[0](14/58368): Loss_D: 124.7308044 Loss_G: 0.4168
===> Epoch[0](15/58368): Loss_D: 125.5501709 Loss_G: 0.4164
===> Epoch[0](16/58368): Loss_D: 124.9440842 Loss_G: 0.4159
===> Epoch[0](17/58368): Loss_D: 124.4784012 Loss_G: 0.4157
===> Epoch[0](18/58368): Loss_D: 124.8331909 Loss_G: 0.4148
===> Epoch[0](19/58368): Loss_D: 124.7789459 Loss_G: 0.4148
===> Epoch[0](20/58368): Loss_D: 124.9267426 Loss_G: 0.4133
===> Epoch[0](21/58368): Loss_D: 124.4301605 Loss_G: 0.4137
===> Epoch[0](22/58368): Loss_D: 124.5855637 Loss_G: 0.4124
===> Epoch[0](23/58368): Loss_D: 124.0562744 Loss_G: 0.4130
===> Epoch[0](24/58368): Loss_D: 125.2767715 Loss_G: 0.4110
===> Epoch[0](25/58368): Loss_D: 124.3785019 Loss_G: 0.4115
===> Epoch[0](26/58368): Loss_D: 123.4750671 Loss_G: 0.4118
===> Epoch[0](27/58368): Loss_D: 124.7357178 Loss_G: 0.4113
===> Epoch[0](28/58368): Loss_D: 124.1584473 Loss_G: 0.4106
===> Epoch[0](29/58368): Loss_D: 124.1722641 Loss_G: 0.4099
===> Epoch[0](30/58368): Loss_D: 124.5135269 Loss_G: 0.4100
===> Epoch[0](31/58368): Loss_D: 124.3946304 Loss_G: 0.4092
===> Epoch[0](32/58368): Loss_D: 123.4331894 Loss_G: 0.4091
===> Epoch[0](33/58368): Loss_D: 123.9753799 Loss_G: 0.4095
===> Epoch[0](34/58368): Loss_D: 124.6061859 Loss_G: 0.4083
===> Epoch[0](35/58368): Loss_D: 123.9417419 Loss_G: 0.4078
===> Epoch[0](36/58368): Loss_D: 124.2400055 Loss_G: 0.4072
===> Epoch[0](37/58368): Loss_D: 123.3945923 Loss_G: 0.4075
===> Epoch[0](38/58368): Loss_D: 124.0347366 Loss_G: 0.4066
===> Epoch[0](39/58368): Loss_D: 123.4848251 Loss_G: 0.4070
===> Epoch[0](40/58368): Loss_D: 123.5581207 Loss_G: 0.4069
===> Epoch[0](41/58368): Loss_D: 123.7680054 Loss_G: 0.4059
===> Epoch[0](42/58368): Loss_D: 123.6264572 Loss_G: 0.4059
===> Epoch[0](43/58368): Loss_D: 124.0728149 Loss_G: 0.4054
===> Epoch[0](44/58368): Loss_D: 124.1695328 Loss_G: 0.4052
===> Epoch[0](45/58368): Loss_D: 123.7110443 Loss_G: 0.4052
===> Epoch[0](46/58368): Loss_D: 123.8877945 Loss_G: 0.4059
===> Epoch[0](47/58368): Loss_D: 123.5818329 Loss_G: 0.4041
===> Epoch[0](48/58368): Loss_D: 124.4120712 Loss_G: 0.4037
===> Epoch[0](49/58368): Loss_D: 123.7107239 Loss_G: 0.4033
===> Epoch[0](50/58368): Loss_D: 124.0108719 Loss_G: 0.4038
===> Epoch[0](51/58368): Loss_D: 122.6284714 Loss_G: 0.4034
===> Epoch[0](52/58368): Loss_D: 123.1049423 Loss_G: 0.4030
===> Epoch[0](53/58368): Loss_D: 122.8548584 Loss_G: 0.4032
===> Epoch[0](54/58368): Loss_D: 123.9958115 Loss_G: 0.4026
===> Epoch[0](55/58368): Loss_D: 122.7839203 Loss_G: 0.4028
===> Epoch[0](56/58368): Loss_D: 123.2269287 Loss_G: 0.4021
===> Epoch[0](57/58368): Loss_D: 123.1159439 Loss_G: 0.4019
===> Epoch[0](58/58368): Loss_D: 122.7409439 Loss_G: 0.4020
===> Epoch[0](59/58368): Loss_D: 123.4162979 Loss_G: 0.4015
===> Epoch[0](60/58368): Loss_D: 122.6483154 Loss_G: 0.4011
===> Epoch[0](61/58368): Loss_D: 123.6004181 Loss_G: 0.4008
===> Epoch[0](62/58368): Loss_D: 123.6784134 Loss_G: 0.4008
===> Epoch[0](63/58368): Loss_D: 122.9986343 Loss_G: 0.4010
===> Epoch[0](64/58368): Loss_D: 122.8530121 Loss_G: 0.4004
===> Epoch[0](65/58368): Loss_D: 122.6409073 Loss_G: 0.4002
===> Epoch[0](66/58368): Loss_D: 123.0934525 Loss_G: 0.4000
===> Epoch[0](67/58368): Loss_D: 122.0476913 Loss_G: 0.4004
===> Epoch[0](68/58368): Loss_D: 124.0841675 Loss_G: 0.3997
===> Epoch[0](69/58368): Loss_D: 122.6003189 Loss_G: 0.3996
===> Epoch[0](70/58368): Loss_D: 122.9215927 Loss_G: 0.3991
===> Epoch[0](71/58368): Loss_D: 122.6334381 Loss_G: 0.3988
===> Epoch[0](72/58368): Loss_D: 122.5647202 Loss_G: 0.3983
===> Epoch[0](73/58368): Loss_D: 121.7526703 Loss_G: 0.3989
===> Epoch[0](74/58368): Loss_D: 121.8846359 Loss_G: 0.3982
===> Epoch[0](75/58368): Loss_D: 122.0008087 Loss_G: 0.3980
===> Epoch[0](76/58368): Loss_D: 123.4387817 Loss_G: 0.3983
===> Epoch[0](77/58368): Loss_D: 123.2295914 Loss_G: 0.3987
===> Epoch[0](78/58368): Loss_D: 122.3822327 Loss_G: 0.3986
===> Epoch[0](79/58368): Loss_D: 122.1736755 Loss_G: 0.3980
===> Epoch[0](80/58368): Loss_D: 122.6103058 Loss_G: 0.3971
===> Epoch[0](81/58368): Loss_D: 122.6361008 Loss_G: 0.3982
===> Epoch[0](82/58368): Loss_D: 121.9303207 Loss_G: 0.3970
===> Epoch[0](83/58368): Loss_D: 122.6951065 Loss_G: 0.3969
===> Epoch[0](84/58368): Loss_D: 121.8697205 Loss_G: 0.3969
===> Epoch[0](85/58368): Loss_D: 122.6621933 Loss_G: 0.3966
===> Epoch[0](86/58368): Loss_D: 122.6541672 Loss_G: 0.3962
===> Epoch[0](87/58368): Loss_D: 121.8004837 Loss_G: 0.3959
===> Epoch[0](88/58368): Loss_D: 121.6627045 Loss_G: 0.3966
===> Epoch[0](89/58368): Loss_D: 121.5786667 Loss_G: 0.3959
===> Epoch[0](90/58368): Loss_D: 120.6752167 Loss_G: 0.3957
===> Epoch[0](91/58368): Loss_D: 120.7876740 Loss_G: 0.3950
===> Epoch[0](92/58368): Loss_D: 120.4974365 Loss_G: 0.3947
===> Epoch[0](93/58368): Loss_D: 122.3922272 Loss_G: 0.3955
===> Epoch[0](94/58368): Loss_D: 121.8048096 Loss_G: 0.3953
===> Epoch[0](95/58368): Loss_D: 122.5662460 Loss_G: 0.3958
===> Epoch[0](96/58368): Loss_D: 122.1867218 Loss_G: 0.3948
===> Epoch[0](97/58368): Loss_D: 121.7981491 Loss_G: 0.3944
===> Epoch[0](98/58368): Loss_D: 121.9568710 Loss_G: 0.3945
===> Epoch[0](99/58368): Loss_D: 121.9824295 Loss_G: 0.3942
===> Epoch[0](100/58368): Loss_D: 121.1546478 Loss_G: 0.3938
===> Epoch[0](101/58368): Loss_D: 121.3416901 Loss_G: 0.3944
===> Epoch[0](102/58368): Loss_D: 121.1229706 Loss_G: 0.3934
===> Epoch[0](103/58368): Loss_D: 121.4108887 Loss_G: 0.3942
===> Epoch[0](104/58368): Loss_D: 121.3021698 Loss_G: 0.3941
===> Epoch[0](105/58368): Loss_D: 121.7288742 Loss_G: 0.3933
===> Epoch[0](106/58368): Loss_D: 121.5626907 Loss_G: 0.3943
===> Epoch[0](107/58368): Loss_D: 120.7796783 Loss_G: 0.3929
===> Epoch[0](108/58368): Loss_D: 120.9535141 Loss_G: 0.3934
===> Epoch[0](109/58368): Loss_D: 120.6684036 Loss_G: 0.3931
===> Epoch[0](110/58368): Loss_D: 120.8933487 Loss_G: 0.3932
===> Epoch[0](111/58368): Loss_D: 121.6505432 Loss_G: 0.3921
===> Epoch[0](112/58368): Loss_D: 119.9069366 Loss_G: 0.3923
===> Epoch[0](113/58368): Loss_D: 119.7930069 Loss_G: 0.3925
===> Epoch[0](114/58368): Loss_D: 120.9352951 Loss_G: 0.3928
===> Epoch[0](115/58368): Loss_D: 121.0120697 Loss_G: 0.3922
===> Epoch[0](116/58368): Loss_D: 120.0581055 Loss_G: 0.3919
===> Epoch[0](117/58368): Loss_D: 120.0414429 Loss_G: 0.3923
===> Epoch[0](118/58368): Loss_D: 121.4120407 Loss_G: 0.3924
===> Epoch[0](119/58368): Loss_D: 120.0255508 Loss_G: 0.3921
===> Epoch[0](120/58368): Loss_D: 119.4310074 Loss_G: 0.3918
===> Epoch[0](121/58368): Loss_D: 121.2583694 Loss_G: 0.3918
===> Epoch[0](122/58368): Loss_D: 120.6989975 Loss_G: 0.3921
===> Epoch[0](123/58368): Loss_D: 120.0833130 Loss_G: 0.3917
===> Epoch[0](124/58368): Loss_D: 120.3667374 Loss_G: 0.3920
===> Epoch[0](125/58368): Loss_D: 120.3933182 Loss_G: 0.3915
===> Epoch[0](126/58368): Loss_D: 119.1336212 Loss_G: 0.3921
===> Epoch[0](127/58368): Loss_D: 119.9264069 Loss_G: 0.3904
===> Epoch[0](128/58368): Loss_D: 120.4601212 Loss_G: 0.3910
===> Epoch[0](129/58368): Loss_D: 120.7483215 Loss_G: 0.3910
===> Epoch[0](130/58368): Loss_D: 120.4908905 Loss_G: 0.3905
===> Epoch[0](131/58368): Loss_D: 121.3800354 Loss_G: 0.3895
===> Epoch[0](132/58368): Loss_D: 120.3293228 Loss_G: 0.3909
===> Epoch[0](133/58368): Loss_D: 119.8415298 Loss_G: 0.3907
===> Epoch[0](134/58368): Loss_D: 120.1727295 Loss_G: 0.3906
===> Epoch[0](135/58368): Loss_D: 119.4341354 Loss_G: 0.3885
===> E                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               